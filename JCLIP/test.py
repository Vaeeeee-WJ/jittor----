import jittor as jt
import jclip as clip
import jittor.nn as nn
import os
from PIL import Image
from tqdm import tqdm
import argparse
import random
import pandas as pd
import numpy as np
from finetune.Tipadapter   import  Tip_adapter
from finetune.cache_module import cache_module
from sklearn.linear_model import LogisticRegression
from utils import generate_prompt, normalize_tensor, count_parameters_in_mb, get_val_text_features, get_date_format
from sklearn.multiclass import OneVsRestClassifier


random.seed(20) 
jt.misc.set_global_seed(20)

def compute_acc_TestSetZ(root_TrainSet, pkl_path, FD_Align_pkl_path, Tip_Adapter_F_pkl_path, cross_modal_pkl_path, classes_path , TestData_path , TestSetZ_label_path, ALPHA =  2.4, BETA = 0.7 ,method_name = None):
    
    """
    root_TrainSet          : è®­ç»ƒé›†çš„æ ¹ç›®å½•
    pkl_path               : clipæ¨¡å‹æƒé‡çš„è·¯å¾„
    FD_Align_pkl_path      : FD_Alignæ–¹æ³•è®­ç»ƒå¾—åˆ°çš„æƒé‡è·¯å¾„
    Tip_Adapter_F_pkl_path : Tip-Adapter-Fæ–¹æ³•è®­ç»ƒå¾—åˆ°çš„æƒé‡è·¯å¾„
    cross_modal_pkl_path   : cross_modal_adapteræ–¹æ³•è®­ç»ƒå¾—åˆ°çš„æƒé‡è·¯å¾„
    classes_path           : classes.txtæ–‡ä»¶çš„è·¯å¾„
    TestData_path          : æµ‹è¯•æ•°æ®é›†çš„è·¯å¾„     (TestSetZ or TestSetA or TestSetB)
    TestSetZ_label_path    : TestSetZ-label.txtæ–‡ä»¶è·¯å¾„
    method_name            : ä½¿ç”¨çš„å¾®è°ƒæ–¹æ³•ï¼Œé»˜è®¤ä¸ºNone,å…¶ä½™å¯é€‰æ‹©çš„æœ‰ ['Tip-Adapter', 'Tip-Adapter-F', 'Linear_Probe', 'cross_modal_Adapter', 'cross_modal+tip_adapter', 'FD-Align', 'WiSE-FT', 'fusion', 'fusion_2']
    ALPHA , BETA           : Tip-Adapterå¾®è°ƒæ–¹æ³•ä¸­çš„è¶…å‚æ•°,é»˜è®¤ä¸º(2.4,0.7)
    """
    
    model, preprocess = clip.load(pkl_path)                            # åŠ è½½è®­ç»ƒè¿‡çš„clipæ¨¡å‹

    text_features  = get_val_text_features(classes_path, model=model)  # ç±»åˆ«çš„æ–‡æœ¬ç‰¹å¾

    num         = 0 # é¢„æµ‹æ­£ç¡®çš„å›¾ç‰‡æ•°é‡

    class_4_path= f'{root_TrainSet}/train_4class.txt' 
    df_label    = pd.read_csv(TestSetZ_label_path, delimiter = '\t',encoding ='utf-8',header = None)     # TestSetZ çš„æ ‡ç­¾ï¼Œç”¨äºè®¡ç®—å‡†ç¡®ç‡
    df_result   = pd.DataFrame(columns=['img_name', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5'])   # ç”¨äºä¿å­˜åœ¨TestSetAä¸Šé¢„æµ‹çš„ç»“æœ
    result_name = f'../results/result{get_date_format()}.txt'                                                       # ä¿å­˜ç»“æœçš„æ–‡ä»¶å

    print(f'Test Dataset is: {TestData_path[-9:-1]}')
    imgs = os.listdir(TestData_path)

    def compute_probs(path_of_img :str, model = model, preprocess = preprocess):    
        '''
        path_of_img   : è¾“å…¥çš„å›¾ç‰‡è·¯å¾„
        return        : ä¸¤ä¸ªè¿”å›å€¼ï¼šç»è¿‡CLIPæ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ¦‚ç‡ ä»¥åŠ ç»è¿‡image_encoderè¾“å‡ºçš„å›¾ç‰‡ç‰¹å¾ 
        '''
        image           = Image.open(path_of_img).convert('RGB')
        image           = preprocess(image).unsqueeze(0)
        # image   = Image_Transform(image, clip_init).choose_best_img().unsqueeze(0)
        image_features  = model.encode_image(image)
        image_features  /= image_features.norm(dim=-1, keepdim=True)
 
        return image_features   

    # è·å–æ‰€æœ‰æµ‹è¯•å›¾åƒçš„ç‰¹å¾
    def get_test_fea(model=model, preprocess=preprocess):
        test_features = []             
        print('loading test data...')
        with jt.no_grad():
            for img in  tqdm(imgs):
                image_features = compute_probs(TestData_path + img, model, preprocess)
                test_features.append(image_features)
        test_features = jt.cat(test_features)
        return test_features
    
    # è·å–æ‰€æœ‰æµ‹è¯•å›¾åƒçš„æ ‡ç­¾
    def get_test_label():
        test_label  = df_label.set_index(0).reindex(imgs)[1].tolist() 
        return test_label
    
    test_label  = get_test_label()  
    
    #------------------------------ä¸ä½¿ç”¨å…¶ä»–å¾®è°ƒæ–¹æ³•,ç›´æ¥æµ‹è¯•------------------------------
    if method_name == None:

        def test(img_fea):
            '''
            img_fea : å›¾åƒç‰¹å¾
            return : è¿”å›é¢„æµ‹çš„Top5çš„ç±»åˆ«
            '''
            test_probs    = (100.0 * img_fea @ text_features.transpose(0, 1)).softmax(dim=-1)
            _, top_labels = test_probs.topk(5)          # top5 predictions
            return top_labels

        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            top5_result = test(get_test_fea())

            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False)  # è½¬æˆtxtç»“æœæ–‡ä»¶
            return num
        
        else:
            top5_result = test(get_test_fea())
            top1_result = top5_result[:,0]
            num = jt.sum(jt.equal(test_label, top1_result))
            print(f"å…±{len(df_label)}å¼ å›¾ç‰‡ï¼Œé¢„æµ‹å®Œæˆï¼")
            return num
        
    #------------------------------è°ƒç”¨å…¶ä»–finetuneæ–¹æ³•------------------------------
    #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” Tip-Adapter â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”#
    elif method_name == 'Tip-Adapter':
        
        print(f'Utilized the {method_name} method!')
        cached_keys , cached_values= Tip_adapter(root_TrainSet, class_4_path, classes_path , model , preprocess)

        def tip_test(test_features, alpha=ALPHA, beta=BETA):
            cache_logits = ((-1) * (beta - beta* test_features @ cached_keys.t())).exp() @ cached_values # [3000,374]
            cache_logits = normalize_tensor(cache_logits)
            # cache_logits /= cache_logits.norm(dim=1, keepdim=True)

            text_probs    = (100.0 * test_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            logits        = alpha * cache_logits + text_probs
            # logits = alpha * cache_logits * text_probs

            _, top_labels  = logits.topk(5)
            return top_labels  # è¿”å›é¢„æµ‹Top5çš„ç±»åˆ« [3000,5]
  
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            test_features = get_test_fea()
            top5_result   = tip_test(test_features, alpha=2.0, beta=3.0)
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False)  # è½¬æˆtxtç»“æœæ–‡ä»¶
            return num
        
        else:
            best_acc = 0
            ALPHA = [0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0,3.2,3.4,3.6,3.8,4.0,4.2,4.4,4.6,4.8,5.0,5.2,5.4,5.6,5.8,6.0,6.2,6.4,6.6]
            BETA  = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0,5.1] 
            test_features = get_test_fea()
            for alpha in ALPHA:
                for beta in BETA:
                    top5_result = tip_test(test_features, alpha, beta)
                    top1_result = top5_result[:,0]
                    num = jt.sum(jt.equal(test_label, top1_result))
                    acc = num/3000
                    if round(float(acc), 4) >  best_acc:
                        best_acc   = round(float(acc), 4)
                        ALPHA_best = alpha
                        BETA_best  = beta
                        print(f'The best acc is {best_acc}, alpha is {ALPHA_best}, beta is {BETA_best}')
            return num

    #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” Tip-Adapter-F:ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”#
    elif method_name == 'Tip-Adapter-F': 

        print(f'Utilized the {method_name} method!')
        cached_keys , cached_values= Tip_adapter(root_TrainSet, class_4_path , classes_path , model , preprocess)

        # åŠ è½½è®­ç»ƒçš„Tip-adapater-F
        adapter                   = nn.Linear(cached_keys.shape[1], cached_keys.shape[0], bias=False)
        adapter.load_state_dict(jt.load(Tip_Adapter_F_pkl_path))

        def tip_F_test(test_features, alpha=0.4, beta=5.1): 
            affinity     = adapter(test_features)
            cache_logits = ((-1) * (beta - beta*  affinity)).exp() @ cached_values # [3000,374]
            # cache_logits = normalize_tensor(cache_logits)
            # cache_logits /= cache_logits.norm(dim=1, keepdim=True)

            text_probs    = (100.0 * test_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            logits        = alpha * cache_logits + text_probs
            # logits = alpha * cache_logits * text_probs

            _, top_labels  = logits.topk(5)
            return top_labels  # è¿”å›é¢„æµ‹Top5çš„ç±»åˆ« [3000,5]
  
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            test_features = get_test_fea()
            top5_result = tip_F_test(test_features, alpha=0.22, beta=4.5)
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ',  index=False, header=False)  # è½¬æˆtxtç»“æœæ–‡ä»¶
            return num
        
        else:
                 
            best_acc = 0
            ALPHA = [0.1,0.2,0.22,0.24,0.26,0.28,0.3,0.32,0.34,0.36,0.38,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0,3.2,3.4,3.6,3.8,4.0,4.2,4.4,4.6,4.8,5.0,5.2,5.4,5.6,5.8,6.0,6.2,6.4,6.6]
            BETA  = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0,5.1] 
            test_features = get_test_fea()
            for alpha in ALPHA:
                for beta in BETA:
                    
                    top5_result = tip_F_test(test_features, alpha, beta)
                    top1_result = top5_result[:,0]
                    test_label  = get_test_label()
                    num = jt.sum(jt.equal(test_label, top1_result))
                    acc = num/3000
                    if round(float(acc), 4) >  best_acc:
                        best_acc = round(float(acc), 4)
                        ALPHA_best = alpha
                        BETA_best  = beta
                        print(f'The best acc is {best_acc}, alpha is {ALPHA_best}, beta is {BETA_best}')
            return num

        
    #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” Linear Probe:çº¿æ€§åˆ†ç±»å¤´ï¼Œå†»ä½ä¸»å¹²ï¼Œä»…å¾®è°ƒä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”#
    # ğŸ“Œåœ¨TestSetZä¸Šçš„æ•ˆæœä¸å¥½,æ‰€ä»¥å¹¶æœªåœ¨TestSetA or B ä¸Šè¿›è¡Œæµ‹è¯•
    elif method_name == 'Linear_Probe':
        
        print(f'Utilized the {method_name} method!')
        
        # æ³¨æ„ï¼šå› ä¸ºè¦ç®€å•è®­ç»ƒä¸€ä¸‹åˆ†ç±»å™¨ï¼Œæ­£å¥½å¯¼å…¥tip_adapterä¸­çš„ç¼“å­˜æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨Tip-adapteræ–¹æ³•
        train_features , train_labels = Tip_adapter(root_TrainSet, class_4_path , classes_path , model , preprocess)
        train_features                = train_features.numpy()
        train_labels                  = jt.argmax(train_labels, dim=1)[0].numpy().astype('float32')

        if 'TestSetA' in TestData_path:
            ...
        else:
            # è®­ç»ƒåˆ†ç±»å™¨
            classifier = LogisticRegression(random_state=0,
                                            C=8.960,
                                            max_iter=3000,
                                            verbose=1)
            classifier.fit(train_features, train_labels)
            
            # åŠ è½½æ‰€æœ‰æµ‹è¯•æ•°æ®
            test_features = []             # å­˜å‚¨æ‰€æœ‰çš„æµ‹è¯•å›¾ç‰‡ç‰¹å¾
            test_label    = []             # å­˜å‚¨æ‰€æœ‰çš„æµ‹è¯•å›¾ç‰‡æ ‡ç­¾
            print('loading test data...')
            with jt.no_grad():
                for img in  tqdm(imgs):
                    image_features = compute_probs(TestData_path + img)
                    test_features.append(image_features)
                    test_label.append(int(df_label.loc[df_label[0] == img, 1].values[0]))
                    
            test_features = jt.cat(test_features).numpy()
            
            print('start predicting...')
            predictions = classifier.predict_proba(test_features)
            for prediction , label  in zip(predictions , test_label):
                prediction = np.asarray(prediction)
                top5_idx = prediction.argsort()[-1:-6:-1]  # å–å‰5ä¸ªé¢„æµ‹ç»“æœ
                output = top5_idx[0]
                if output == label:
                    num += 1    
            return num
    
    elif method_name == 'cross_modal_Adapter':

        print(f'Utilized the {method_name} method!')
        from finetune.Cross_modal_Adapter import logitHead

        model.add_module('cross_logit', logitHead(get_val_text_features(classes_path, model)))
        model.load_state_dict(jt.load(pkl_path))

        model1, preprocess1 = clip.load(cross_modal_pkl_path)

        test_features_clip = get_test_fea(model1, preprocess=preprocess1)
        text_features  = get_val_text_features(classes_path, model=model1) # ç±»åˆ«çš„æ–‡æœ¬ç‰¹å¾

        def cross_modal_Adapter_test(test_features, alpha=ALPHA, beta=BETA):

            logits1 =(100.0*model.cross_logit(test_features)).softmax(dim=-1)
            logits2 = (100.0 * test_features_clip @ text_features.transpose(0, 1)).softmax(dim=-1)

            logits = alpha * logits2 + logits1*beta

            _, top_labels  = logits.topk(5)
            return top_labels  # è¿”å›é¢„æµ‹Top5çš„ç±»åˆ« 
        
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            test_features = get_test_fea()
            top5_result = cross_modal_Adapter_test(test_features, alpha=ALPHA, beta=BETA)
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False)  # è½¬æˆtxtç»“æœæ–‡ä»¶
            return num
        
        else:
                         
            best_acc = 0
            ALPHA = [0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0,3.2,3.4,3.6,3.8,4.0,4.2,4.4,4.6,4.8,5.0,5.2,5.4,5.6,5.8,6.0,6.2,6.4,6.6]
            BETA  = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0,5.1] 
            test_features = get_test_fea()
            for alpha in ALPHA:
                for beta in BETA:
                    
                    top5_result = cross_modal_Adapter_test(test_features, alpha, beta)
                    top1_result = top5_result[:,0]
                    num = jt.sum(jt.equal(test_label, top1_result))
                    acc = num/3000
                    if round(float(acc), 4) >  best_acc:
                        best_acc = round(float(acc), 4)
                        ALPHA_best = alpha
                        BETA_best  = beta
                        print(f'The best acc is {best_acc}, alpha is {ALPHA_best}, beta is {BETA_best}')
            return num

    #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” cross_modal+tip_adapter : ä¸¤ç§å¾®è°ƒæ–¹æ³•çš„ç»“åˆï¼Œå³è·¨æ¨¡æ€è®­ç»ƒ+ç¼“å­˜æ¨¡å‹å¾®è°ƒâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”#
    elif method_name == 'cross_modal+tip_adapter':
 
        print(f'Utilized the {method_name} method!')
        
        train_img_features, train_txt_features,  train_labels = cache_module(root_TrainSet, class_4_path , classes_path , model , preprocess)
        train_img_features, train_txt_features                = train_img_features.numpy(), train_txt_features.numpy()
        # train_labels                                          = jt.argmax(train_labels, dim=1)[0].numpy().astype('float32')
        train_features = np.concatenate((train_img_features, train_txt_features), axis=0)
        train_labels   = np.concatenate((train_labels, train_labels), axis=0)
        # è®­ç»ƒåˆ†ç±»å™¨
        classifier = OneVsRestClassifier(LogisticRegression(random_state=0,
                                        C=8.960,
                                        max_iter=6000,
                                        verbose=1))
        classifier.fit(train_features, train_labels)
        
        # åŠ è½½æ‰€æœ‰æµ‹è¯•æ•°æ®
        print('loading test data...')
        test_features = get_test_fea().numpy()
        
        def cmta_test(alpha=0.5, beta=0.1):    # The best acc is 0.7547, alpha is 1.4, beta is 0.9, gamma is 0.1
            # print('start predicting...')
            predictions = classifier.predict_proba(test_features)
            pre_similitys = (100.0 * jt.array(test_features) @ text_features.transpose(0, 1)).softmax(dim=-1)

            x = predictions
            y = pre_similitys.numpy()

            logits = alpha*x + beta*y
            # logits = 0.8*x*  0.23*y 
            top5_result = np.flip(np.argsort(logits, axis=1)[:, -5:], axis=1) # np.array():åŒ…å«æ•´ä¸ªæ•°æ®é›†top5çš„é¢„æµ‹ç»“æœ
            return top5_result

        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            
            top5_result = cmta_test(alpha=7.0, beta=1.2)
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result['img_name'] = imgs
            df_result.to_csv(result_name, sep=' ', index=False, header=False) 
            
        else:
            best_acc = 0
            ALPHA = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.2,2.4,2.6,2.8,3.0,3.2,3.4,3.6,3.8,4.0,4.2,4.4,4.6,4.8,5.0,5.2,5.4,5.6,5.8,6.0,6.2,6.4,6.6,6.8,7.0,7.2,7.4,7.6,7.8,8.0,8.2,8.4,8.6,8.8,9.0,9.2,9.4,9.6,9.8,10.0,10.2,10.4,10.6,10.8,11.0,11.2,11.4,11.6,11.8,12.0,12.2,12.4,12.6,12.8,13.0,13.2,13.4,13.6,13.8,14.0,14.2,14.4,14.6,14.8,15.0,15.2]
            BETA  = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0] 
            for alpha in ALPHA:
                for beta in BETA:
                    top5_result = cmta_test(alpha, beta)
                    top1_result = top5_result[:,0]
                    num = jt.sum(jt.equal(np.asarray(test_label), top1_result))
                    acc = num/3000
                    if round(float(acc), 4) >  best_acc:
                        best_acc = round(float(acc), 4)
                        ALPHA_best = alpha
                        BETA_best  = beta
                        print(f'The best acc is {best_acc}, alpha is {ALPHA_best}, beta is {BETA_best}')

            # top1_result = cmta_test()[:, 0]
            # num = jt.sum(jt.equal(np.asarray(test_label), top1_result))
            return num
    

    elif method_name == 'FD-Align':

        print(f'Utilized the {method_name} method!')
        from finetune.FD_Align import Prototype
        class_prototype, prompt_prototype= Prototype(classes_path)
        
        def FD_Align_test(img_fea):
            '''
            img_fea : æµ‹è¯•å›¾åƒç‰¹å¾
            return  : è¿”å›é¢„æµ‹çš„Top5ç±»åˆ«
            '''
            text_probs = (100.0 * img_fea @ class_prototype.transpose(0, 1)).softmax(dim=-1)
            _, top_labels = text_probs.topk(5)
            return top_labels  
        
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            top5_result = FD_Align_test(get_test_fea())
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False) 
            return num
        else:
            top5_result = FD_Align_test(get_test_fea())
            top1_result = top5_result[:,0]
            num = jt.sum(jt.equal(test_label, top1_result))
            print(f"å…±{len(df_label)}å¼ å›¾ç‰‡ï¼Œé¢„æµ‹å®Œæˆï¼")
            return num
    
    elif method_name == 'WiSE-FT':

        print(f'Utilized the {method_name} method!')
        from jclip.model import build_model
        from jclip.clip  import _transform
        
        def wise_test(alpha):
    
            added_dict    = { key: alpha* weights_1.get(key, 0) + (1-alpha) * weights_2.get(key, 0) for key in set(weights_1) | set(weights_2)}
            model_12      = build_model(added_dict)
            preprocess_12 = _transform(model_12.visual.input_resolution)
            model_12.eval()
            text_features = get_val_text_features(classes_path, model_12) 
            image_features= get_test_fea(model=model_12, preprocess=preprocess_12)
            test_probs    = (100.0 * image_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            _, top_labels = test_probs.topk(5)          # top5 predictions
            return top_labels

        
        model_1, preprocess_1 = clip.load(pkl_path)   
        model_2, preprocess_2 = clip.load('another_pkl_path')
        
        weights_1 = model_1.state_dict()
        weights_2 = model_2.state_dict()
        
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            top5_result = wise_test(0.2)
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False) 
        
        else:
            best_acc   = 0
            best_alpha = 0
            for ALPHA in np.arange(0.1, 1, 0.01):
                top5_result   = wise_test(ALPHA)
                top1_result = top5_result[: ,0]
                num         = jt.sum(jt.equal(test_label, top1_result))
                acc         = num / 3000
                if round(float(acc), 4) >  best_acc:
                    best_acc   = round(float(acc), 4)
                    best_alpha = ALPHA
                    print(f'The best acc is {best_acc} ; best x is : {best_alpha}')
            print(f"å…±{len(df_label)}å¼ å›¾ç‰‡ï¼Œé¢„æµ‹å®Œæˆï¼")
            print("Best alpha is : ", best_alpha)
            return num

    
    
    
    
    # è®­ç»ƒçš„clipæ¨¡å‹ + Tip-adapter-F + FD-Align + cross_modal_adapter
    elif method_name == 'fusion':
        print(f'Utilized the {method_name} method!')               
        
        from finetune.FD_Align import Prototype
        class_prototype, prompt_prototype= Prototype(classes_path)
        
        def get_logits_FD_Align(pkl_FD):
            
            model_FD_Align, preprocess_FD_Align = clip.load(pkl_FD)          
            test_features   = get_test_fea(model_FD_Align, preprocess_FD_Align)
            
            text_probs = (100.0 * test_features @ class_prototype.transpose(0, 1)).softmax(dim=-1)
            return text_probs, count_parameters_in_mb(model_FD_Align)  

        def get_logits_Tip_Adapter_F(pkl_TAF, alpha, beta):
            cached_keys , cached_values= Tip_adapter(root_TrainSet, class_4_path , classes_path , model , preprocess)

            # åŠ è½½è®­ç»ƒçš„Tip-adapater-F
            adapter       = nn.Linear(cached_keys.shape[1], cached_keys.shape[0], bias=False)
            adapter.load_state_dict(jt.load(pkl_TAF)) 

            test_features = get_test_fea() 
            affinity      = adapter(test_features)
            cache_logits  = ((-1) * (beta - beta*  affinity)).exp() @ cached_values 

            text_probs    = (100.0 * test_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            logits        = alpha * cache_logits + text_probs
            # logits        = cache_logits 
            return logits, count_parameters_in_mb(adapter)
        
        def get_logits_cross_modal(pkl_cross):
            from finetune.Cross_modal_Adapter import logitHead

            model.add_module('cross_logit', logitHead(get_val_text_features(classes_path, model)))
            model.load_state_dict(jt.load(pkl_cross))

            test_features = get_test_fea(model)
            text_probs = (100.0 * model.cross_logit(test_features)).softmax(dim=-1)
            return text_probs, count_parameters_in_mb(model)

        
        def get_logits_clip_train(pkl_clip):
            img_fea       = get_test_fea(model, preprocess)
            test_probs    = (100.0 * img_fea @ text_features.transpose(0, 1)).softmax(dim=-1)
            return test_probs, count_parameters_in_mb(model)

        logits_FD_Align,      parameters_0   = get_logits_FD_Align(FD_Align_pkl_path)
        logits_Tip_Adapter_F, parameters_1   = get_logits_Tip_Adapter_F(Tip_Adapter_F_pkl_path, alpha=1.4, beta=1.3)
        logits_clip, parameters_2            = get_logits_clip_train(pkl_path)
        logits_cross_modal,   parameters_3   = get_logits_cross_modal(cross_modal_pkl_path)

        total_parameters = parameters_0 + parameters_1 + parameters_2 + parameters_3
        print(f'The total number of parameters used by the model is: {total_parameters:.2f} Mb') 
        
        def fusion_test(logits_FD_Align, logits_Tip_Adapter_F, logits_cross_modal, X, Y, Z):
            logits  = X * logits_Tip_Adapter_F + Y * logits_FD_Align + Z * logits_cross_modal
            _, top_labels = logits.topk(5)
            return top_labels
        
        if 'TestSetA' in TestData_path or 'TestSetB' in TestData_path:
            top5_result           = fusion_test(logits_FD_Align, logits_Tip_Adapter_F, logits_cross_modal, X=0.04, Y=0.53, Z=0.43)
            df_result['img_name'] = imgs
            df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
            df_result.to_csv(result_name, sep=' ', index=False, header=False) 
        else:
            best_acc   = 0
            X_list     = np.arange(0.00, 1.00, 0.02)
            for X in X_list:
                for Y in np.arange(0.00, 1-X, 0.02):
                    Z = round(1-X-Y, 2)
                    top1_result   = fusion_test(logits_FD_Align, logits_clip, logits_cross_modal, X=X, Y=Y, Z=Z)[:,0]
                    num = jt.sum(jt.equal(test_label, top1_result))
                    acc = num / 3000
                    if round(float(acc), 4) >  best_acc:
                        best_acc   = round(float(acc), 4)
                        print(f'The best acc is {best_acc} ; best x is : {X}, best y is : {Y}, best z is : {Z}')
            return num
    
   
   
    # è®­ç»ƒå’Œçš„clipæ¨¡å‹ + ä½¿ç”¨Tip-adapter-F æ–¹æ³•å¾®è°ƒçš„clipæ¨¡å‹
    elif method_name == 'fusion_2':
        
        print(f'Utilized the {method_name} method!')

        test_features    = get_test_fea()

        def get_clip_result():
            text_probs       = (100.0 * test_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            top5_result      = text_probs.topk(5)[1] 
            return top5_result, count_parameters_in_mb(model)

        def get_Tip_adapater_F_result(pkl_TAF, alpha, beta):
            cached_keys , cached_values= Tip_adapter(root_TrainSet, class_4_path , classes_path , model , preprocess)

            # åŠ è½½è®­ç»ƒçš„Tip-adapater-F
            adapter       = nn.Linear(cached_keys.shape[1], cached_keys.shape[0], bias=False)
            adapter.load_state_dict(jt.load(pkl_TAF)) 

            affinity      = adapter(test_features)
            cache_logits  = ((-1) * (beta - beta*  affinity)).exp() @ cached_values 

            text_probs    = (100.0 * test_features @ text_features.transpose(0, 1)).softmax(dim=-1)
            logits        = alpha * cache_logits + text_probs

            top5_result   = logits.topk(5)[1]
            return top5_result, count_parameters_in_mb(adapter)
        
        def result_fusion(top5_result_clip, top5_result_TAF):

            '''
            å¯¹äºtop5_result_clipé¢„æµ‹çš„ç»“æœï¼Œå³è®­ç»ƒåçš„clipæ¨¡å‹é¢„æµ‹çš„ç»“æœï¼š
            å¦‚æœé¢„æµ‹çš„ç±»åˆ«åœ¨è®­ç»ƒé›†ä¸Šæœªå‡ºç°è¿‡ï¼Œåˆ™ä¿ç•™ï¼›åä¹‹ï¼Œåˆ™æ›¿æ¢æˆä½¿ç”¨äº†Tip-adapter-Fæ–¹æ³•é¢„æµ‹çš„ç»“æœ
            '''
            index                   = np.where(top5_result_clip < 374) 
            top5_result_clip[index] = top5_result_TAF[index]
            return top5_result_clip
        
        top5_result_clip, parameters_1 = get_clip_result()
        top5_result_TAF,  parameters_2 = get_Tip_adapater_F_result(Tip_Adapter_F_pkl_path, alpha=2.4, beta=0.7)
    
        total_parameters = parameters_1 + parameters_2
        print(f'The total number of parameters used by the model is: {total_parameters:.2f} Mb') 

        top5_result   = result_fusion(top5_result_clip, top5_result_TAF)

        # top1_result   = top5_result[:,0]
        # num = jt.sum(jt.equal(test_label, top1_result))
        # print(num / 3000)

        df_result['img_name'] = imgs
        df_result[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']] = top5_result
        df_result.to_csv(result_name, sep=' ', index=False, header=False) 

        
        

if __name__ == "__main__":

    jt.flags.use_cuda = 1  

    root_TrainSet = r'E:\Competition1'
    
    pkl_path               = "E:\Competition1\Weights\CLIP-0820.pkl"
    Tip_Adapter_F_pkl_path = "E:\Competition1\Weights\Tip_adapter_F-0820.pkl"
    
    TestData_path = f"{root_TrainSet}\TestSetB/"           # TestSetA | TestSetB | TestSetZ
    label_path    = f"{root_TrainSet}\TestSetZ-label.txt"
    classes_path  = f"{root_TrainSet}\classes_b.txt"

    FD_Align_pkl_path      = ""
    os.environ['ROOT_PATH']= root_TrainSet
    cross_modal_pkl_path   = ""


    method_name   = 'fusion_2'
    num           = compute_acc_TestSetZ(root_TrainSet, pkl_path, FD_Align_pkl_path, Tip_Adapter_F_pkl_path, cross_modal_pkl_path, classes_path , TestData_path ,label_path, method_name = method_name)
    if 'TestSetZ' in TestData_path:
        print(f"è¯¥æ¨¡å‹åœ¨{TestData_path[-9:-1]}æ•°æ®é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ä¸ºï¼š{num / 3000:.4f}")
    else:
        print(f'è¯¥æ¨¡å‹åœ¨{TestData_path[-9:-1]}æ•°æ®é›†ä¸Šé¢„æµ‹å®Œæˆï¼')
